{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598423888013
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'CapstoneProject'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1617518210654
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\r\n",
        "\r\n",
        "import os\r\n",
        "import zipfile\r\n",
        "os.environ['KAGGLE_USERNAME'] = \"chaamp\"\r\n",
        "os.environ['KAGGLE_KEY'] = \"26be8486f6a035048aa3e8c49d9001cd\"\r\n",
        "\r\n",
        "\r\n",
        "! kaggle datasets download -d chaamp/language-recognition\r\n",
        "\r\n",
        "path='language-recognition.zip'\r\n",
        "tar='Users/odl_user_141832/'\r\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\r\n",
        "    zip_ref.extractall('')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (4.58.0)\n",
            "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: python-slugify in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (1.25.11)\n",
            "Requirement already satisfied: six>=1.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-slugify->kaggle) (1.3)\n",
            "language-recognition.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617518231744
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openpyxl"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.0.7)\r\n",
            "Requirement already satisfied: et-xmlfile in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from openpyxl) (1.0.1)\r\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction\r\n",
        "\r\n",
        "df=pd.read_excel('trn.xlsx',engine='openpyxl',index_col=0)\r\n"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617521580541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "                   0  1\n0  I'll forgive you.  0\n1       You're wise.  0\n2      It's hideous.  0\n3      I'm not well.  0\n4    You seem upset.  0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'll forgive you.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>You're wise.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It's hideous.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I'm not well.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You seem upset.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617521591479
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\r\n",
        "import re\r\n",
        "from itertools import combinations\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "def three_gram(a):\r\n",
        "  ans=[]\r\n",
        "  for i in a:\r\n",
        "    tmp=[]\r\n",
        "    for j in i:\r\n",
        "      n=len(j)\r\n",
        "      if n>2:\r\n",
        "        for k in range(n-2):\r\n",
        "          tmp.append(j[k:k+3])\r\n",
        "    ans.append(tmp)\r\n",
        "  return ans\r\n",
        "\r\n",
        "def create_vocab(data):\r\n",
        "  df=data.copy()\r\n",
        "  a=df.groupby(1)\r\n",
        "  d={}\r\n",
        "  for i,g in a:\r\n",
        "    d[i]=g[0].tolist()\r\n",
        "\r\n",
        "  for i in range(8):\r\n",
        "    # Lower case the strings\r\n",
        "    d[i]=[x.lower() for x in d[i]]\r\n",
        "    \r\n",
        "    # Remove spacial character and numbers\r\n",
        "    d[i]=[re.sub('\\W+',' ', x) for x in d[i]]\r\n",
        "    d[i]=[re.sub(r'\\d+', '', x) for x in d[i]]\r\n",
        "    \r\n",
        "    # strip the strings\r\n",
        "    d[i]=list(map(str.strip,d[i]))\r\n",
        "\r\n",
        "    #split the strings\r\n",
        "    d[i]=[x.split() for x in d[i]]\r\n",
        "\r\n",
        "  # Create a vocabulary of 1st 250 character 3-gram \r\n",
        "\r\n",
        "  # create a counter\r\n",
        "  count_vec={}\r\n",
        "  for i in range(8):\r\n",
        "    x=three_gram(d[i])\r\n",
        "    c=Counter()\r\n",
        "    x=[Counter(k) for k in x]\r\n",
        "    for j in x:\r\n",
        "      c=c+j\r\n",
        "    count_vec[i]=c\r\n",
        "  # sort the keys and vocab\r\n",
        "  voc={}\r\n",
        "  vocab=[]\r\n",
        "  for i in range(8):\r\n",
        "    count_vec[i]={k: v for k, v in sorted(count_vec[i].items(), key=lambda item: item[1],reverse=True)}\r\n",
        "    l=list(count_vec[i].keys())[:200]\r\n",
        "    vocab=vocab+l\r\n",
        "    voc[i]=l\r\n",
        "  vocab=list(set(vocab))\r\n",
        "  return vocab\r\n",
        "\r\n",
        "\r\n",
        "def feature_extraction(data):\r\n",
        "  #group the data by languages\r\n",
        "  trn=data.copy()\r\n",
        "  a=trn.groupby(1)\r\n",
        "  ftr={}\r\n",
        "  vocab=create_vocab(trn)\r\n",
        "  vectorizer=CountVectorizer(analyzer='char',ngram_range=(3,3),vocabulary=vocab)\r\n",
        "  for i,g in a:\r\n",
        "    x=list(set(g[0].tolist()))\r\n",
        "    ftr[i]=vectorizer.fit_transform(x).toarray()\r\n",
        "  for i in range(8):\r\n",
        "    ftr[i]=ftr[i][~np.all(ftr[i]==0,axis=1)]\r\n",
        "\r\n",
        "# Combine all the arrays\r\n",
        "\r\n",
        "  # create labels\r\n",
        "  lbl={}\r\n",
        "  ftr_={}\r\n",
        "  for i in range(8):\r\n",
        "    lbl[i]=np.array([i]*ftr[i].shape[0]).reshape((ftr[i].shape[0],1))\r\n",
        "    ftr_[i]=np.append(ftr[i],lbl[i],1)\r\n",
        "    if i==0:\r\n",
        "      train=ftr_[i]\r\n",
        "    else:\r\n",
        "      train=np.append(train,ftr_[i],0)\r\n",
        "\r\n",
        "  #Shuffle the dataset\r\n",
        "  np.random.shuffle(train)\r\n",
        "\r\n",
        "  trainx=train[:,:-1]\r\n",
        "  trainy=train[:,-1]\r\n",
        "\r\n",
        "  return train"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617522356080
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=feature_extraction(df)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617522536846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "key = 'LR data'\r\n",
        "if key in ws.datasets.keys():\r\n",
        "    dataset = ws.datasets[key]\r\n",
        "    print(\"Dataset found\")\r\n",
        "    train = Dataset.Tabular.from_delimited_files([(datastore,'trn.csv')])\r\n",
        "\r\n",
        "else:\r\n",
        "    df=pd.read_excel('trn.xlsx',engine='openpyxl',index_col=0)\r\n",
        "    df.to_csv('trn.csv',index = False)\r\n",
        "    datastore = ws.get_default_datastore()\r\n",
        "    datastore.upload_files(files = ['./trn.csv'])\r\n",
        "    train = Dataset.Tabular.from_delimited_files([(datastore,'trn.csv')])\r\n",
        "    train = train.register(ws,key)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617518262917
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Compute instance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "\r\n",
        "cpu_cluster_name = \"compute-cluster\"\r\n",
        "\r\n",
        "# Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Creating a new compute cluster...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\r\n",
        "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\r\n",
        "\r\n",
        "# Can poll for a minimum number of nodes and for a specific timeout. \r\n",
        "# If no min node count is provided it uses the scale settings for the cluster.\r\n",
        "compute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617518373373
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\"primary_metric\":\"accuracy\",\n",
        "                   \"experiment_timeout_minutes\":20,\n",
        "                   \"enable_early_stopping\":True,\n",
        "                   'enable_tf':True,\n",
        "                   'enable_dnn':True,\n",
        "                   'blocked_models': None,\n",
        "                   \"max_concurrent_iterations\": 4}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(compute_target = compute_target, task = 'classification', training_data = train, label_column_name ='1',**automl_settings)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Tensorflow support within AutoML is being deprecated.\n",
            "WARNING:root:tensorflow module is not installed\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1617521438529
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on remote.\n",
            "No run_configuration provided, running on compute-cluster with default configuration\n",
            "Running on remote compute: compute-cluster\n",
            "Parent Run ID: AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689\n",
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Something went wrong while printing the experiment progress but the run is still executing on the compute target. \n",
            "Please check portal for updated status: https://ml.azure.com/experiments/CapstoneProject/runs/AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-141913/workspaces/quick-starts-ws-141913\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1617520535524
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "718a5e776171460c85918a2c4931a607"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/CapstoneProject/runs/AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-141913/workspaces/quick-starts-ws-141913\", \"run_id\": \"AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689\", \"run_properties\": {\"run_id\": \"AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689\", \"created_utc\": \"2021-04-04T06:44:47.710094Z\", \"properties\": {\"num_iterations\": \"1000\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"accuracy\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": null, \"target\": \"compute-cluster\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"CapstoneProject\\\",\\\"subscription_id\\\":\\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\",\\\"resource_group\\\":\\\"aml-quickstarts-141913\\\",\\\"workspace_name\\\":\\\"quick-starts-ws-141913\\\",\\\"region\\\":\\\"southcentralus\\\",\\\"compute_target\\\":\\\"compute-cluster\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"remote\\\",\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"enable_batch_run\\\":false,\\\"iterations\\\":1000,\\\"primary_metric\\\":\\\"accuracy\\\",\\\"task_type\\\":\\\"classification\\\",\\\"data_script\\\":null,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":null,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":null,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":1,\\\"max_concurrent_iterations\\\":4,\\\"iteration_timeout_minutes\\\":null,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":20,\\\"experiment_exit_score\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"TensorFlowDNN\\\"],\\\"supported_models\\\":[\\\"MultinomialNaiveBayes\\\",\\\"GradientBoosting\\\",\\\"DecisionTree\\\",\\\"SGD\\\",\\\"KNN\\\",\\\"XGBoostClassifier\\\",\\\"TensorFlowDNN\\\",\\\"LogisticRegression\\\",\\\"SVM\\\",\\\"ExtremeRandomTrees\\\",\\\"AveragedPerceptronClassifier\\\",\\\"LinearSVM\\\",\\\"TensorFlowLinearClassifier\\\",\\\"BernoulliNaiveBayes\\\",\\\"LightGBM\\\",\\\"RandomForest\\\"],\\\"private_models\\\":[],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"azureml_automl.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":false,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":\\\"STANDARD_D2_V2\\\",\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":true,\\\"scenario\\\":\\\"SDK-1.13.0\\\",\\\"environment_label\\\":null,\\\"save_mlflow\\\":false,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":true,\\\"enable_early_stopping\\\":true,\\\"early_stopping_n_iters\\\":10,\\\"metrics\\\":null,\\\"enable_metric_confidence\\\":false,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":true,\\\"ensemble_iterations\\\":15,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":null,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"1\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"_local_managed_run_id\\\":null,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"maximize\\\",\\\"preprocess\\\":true}\", \"DataPrepJsonString\": \"{\\\\\\\"training_data\\\\\\\": \\\\\\\"{\\\\\\\\\\\\\\\"blocks\\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"4a7cc935-9de7-4a34-a0fd-db703f897b0e\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"datastores\\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"trn.csv\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"aml-quickstarts-141913\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"subscription\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"quick-starts-ws-141913\\\\\\\\\\\\\\\"}]}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"88c75a65-ac39-4e2e-8378-b4e475d3f674\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.ParseDelimitedBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"columnHeadersMode\\\\\\\\\\\\\\\": 3, \\\\\\\\\\\\\\\"fileEncoding\\\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\\\"handleQuotedLineBreaks\\\\\\\\\\\\\\\": false, \\\\\\\\\\\\\\\"preview\\\\\\\\\\\\\\\": false, \\\\\\\\\\\\\\\"separator\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"skipRows\\\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\\\"skipRowsMode\\\\\\\\\\\\\\\": 0}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2822becf-98a9-44f3-8853-6ee44a910184\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"columns\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\"Path\\\\\\\\\\\\\\\"]}}}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"007feebc-b6d2-4487-9c41-e291576c751a\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.SetColumnTypesBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"columnConversion\\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\\"column\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\\\": 0}, {\\\\\\\\\\\\\\\"column\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\\\": 2}]}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}], \\\\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\\"meta\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"735194a6-6ca2-4cd3-8d5e-8fa1df93becd\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"tabular\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0484db5c-fd20-4379-ac69-0570aa538b61\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"southcentralus\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"partition_keys\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\"}}\\\\\\\", \\\\\\\"activities\\\\\\\": 0}\", \"EnableSubsampling\": null, \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.24.0\\\", \\\"azureml-train\\\": \\\"1.24.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.24.0\\\", \\\"azureml-train-core\\\": \\\"1.24.0\\\", \\\"azureml-train-automl\\\": \\\"1.24.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.24.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.24.0\\\", \\\"azureml-tensorboard\\\": \\\"1.24.0\\\", \\\"azureml-telemetry\\\": \\\"1.24.0\\\", \\\"azureml-sdk\\\": \\\"1.24.0\\\", \\\"azureml-samples\\\": \\\"0+unknown\\\", \\\"azureml-pipeline\\\": \\\"1.24.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.24.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.24.0\\\", \\\"azureml-opendatasets\\\": \\\"1.24.0\\\", \\\"azureml-model-management-sdk\\\": \\\"1.0.1b6.post1\\\", \\\"azureml-mlflow\\\": \\\"1.24.0\\\", \\\"azureml-interpret\\\": \\\"1.24.0\\\", \\\"azureml-explain-model\\\": \\\"1.24.0\\\", \\\"azureml-defaults\\\": \\\"1.24.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.24.0\\\", \\\"azureml-dataprep\\\": \\\"2.11.1\\\", \\\"azureml-dataprep-rslex\\\": \\\"1.9.0\\\", \\\"azureml-dataprep-native\\\": \\\"30.0.0\\\", \\\"azureml-datadrift\\\": \\\"1.24.0\\\", \\\"azureml-core\\\": \\\"1.24.0\\\", \\\"azureml-contrib-services\\\": \\\"1.24.0\\\", \\\"azureml-contrib-server\\\": \\\"1.24.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"1.24.0\\\", \\\"azureml-contrib-pipeline-steps\\\": \\\"1.24.0\\\", \\\"azureml-contrib-notebook\\\": \\\"1.24.0\\\", \\\"azureml-contrib-gbdt\\\": \\\"1.24.0\\\", \\\"azureml-contrib-fairness\\\": \\\"1.24.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.24.0\\\", \\\"azureml-cli-common\\\": \\\"1.24.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.24.0\\\", \\\"azureml-automl-dnn-nlp\\\": \\\"1.24.0\\\", \\\"azureml-automl-core\\\": \\\"1.24.0\\\", \\\"azureml-accel-models\\\": \\\"1.24.0\\\"}\", \"_aml_system_scenario_identification\": \"Remote.Parent\", \"ClientType\": \"SDK\", \"environment_cpu_name\": \"AzureML-AutoML-DNN\", \"environment_cpu_label\": \"prod\", \"environment_gpu_name\": \"AzureML-AutoML-DNN-GPU\", \"environment_gpu_label\": \"prod\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"CancelUri\": \"https://southcentralus.experiments.azureml.net/jasmine/v1.0/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourceGroups/aml-quickstarts-141913/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-141913/experimentids/fb7f44a2-f2c2-4ac3-a47e-d09e1c4bf298/cancel/AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689\", \"ClientSdkVersion\": \"1.24.0\", \"snapshotId\": \"00000000-0000-0000-0000-000000000000\", \"SetupRunId\": \"AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689_setup\", \"SetupRunContainerId\": \"dcid.AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689_setup\", \"errors\": \"Run timed out. No model completed training in the specified time. Possible solutions: \\n1) Please check if there are enough compute resources to run the experiment. \\n2) Increase experiment timeout when creating a run. \\n3) Subsample your dataset to decrease featurization/training time. \"}, \"tags\": {\"model_explain_run\": \"best_run\", \"_aml_system_azureml.automlComponent\": \"AutoML\"}, \"end_time_utc\": \"2021-04-04T07:09:51.277925Z\", \"status\": \"Failed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:25:03\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689\", \"categories\": [0, 1], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_4a93314b-61c5-471f-ba41-6a4622ee0689\", \"categories\": [0, 1], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\"]}]}], \"run_logs\": \"\\nError occurred: Run timed out. No model completed training in the specified time. Possible solutions: \\n1) Please check if there are enough compute resources to run the experiment. \\n2) Increase experiment timeout when creating a run. \\n3) Subsample your dataset to decrease featurization/training time. \\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.24.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1617520535974
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}